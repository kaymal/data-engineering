{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Automation in Python\n",
    "\n",
    "Contents:\n",
    "- IPython Shell Commands\n",
    "- Subprocess\n",
    "- File Systems\n",
    "- Command Line Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython Shell Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fr']\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "\n",
    "days = ['Mo', 'Tu', 'We', 'Th', 'Fr']\n",
    "\n",
    "# Print a random day of the week\n",
    "print(choices(days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mo']\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"from random import choices;days = ['Mo', 'Tu', 'We', 'Th', 'Fr'];print(choices(days))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-c` is used to execute a program passed as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                      \u001b[34mmy_package\u001b[m\u001b[m/\n",
      "command-line-automation.ipynb  setup.py\n",
      "\u001b[34mdata\u001b[m\u001b[m/                          software-engineering.ipynb\n",
      "data-engineering.ipynb         spark-script.py\n",
      "data-pipeline.ipynb            stable-req.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing a variable from a shell command in IPython\n",
    "\n",
    "The output of shell commands can be assigned to a variable and stored in Python `SList` data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['command-line-automation.ipynb', 'data-engineering.ipynb', 'data-pipeline.ipynb', 'software-engineering.ipynb']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store a variable from a shell command in IPython\n",
    "var = !ls -h *.ipynb\n",
    "\n",
    "# Print the resulting variable\n",
    "print(var)\n",
    "\n",
    "# Print the number of .ipynb files in the current directory\n",
    "len(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.utils.text.SList"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/athlete_events.csv data/flights.csv        data/noc_regions.csv\n"
     ]
    }
   ],
   "source": [
    "!ls */*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `%%bash` magic syntax to capture the output of a script in IPython. For instance, below code runs a code block with output stored in the variable `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out output --err error\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "command-line-automation.ipynb\n",
      "data\n",
      "data-engineering.ipynb\n",
      "data-pipeline.ipynb\n",
      "my_package\n",
      "setup.py\n",
      "software-engineering.ipynb\n",
      "spark-script.py\n",
      "stable-req.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One good use case is needing to download machine learning training data using `wget`, then uncompressing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWK\n",
    "\n",
    "`awk` is a scripting language used for manipulating data, generating reports and text processing. \n",
    "\n",
    "AWK Operations:\n",
    "- Scans a file line by line\n",
    "- Splits each input line into fields\n",
    "- Compares input line/fields to pattern\n",
    "- Performs action(s) on matched lines\n",
    "\n",
    "Useful For:\n",
    "- Transforming data files\n",
    "- Producing formatted reports\n",
    "\n",
    "> Awk is a tool that is used often on the Unix command line because it understands how to deal with whitespace delimited output from shell commands. The awk command works well at grabbing fields from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111923\n"
     ]
    }
   ],
   "source": [
    "# Sum the file sizes\n",
    "!ls -l | awk '{SUM+=$5} END {print SUM}'\n",
    "\n",
    "# -l: use a long listing format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation with SList Data Type\n",
    "\n",
    "`SList` is an IPython data type which enables a user to perform powerful operations on shell commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.utils.text.SList"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three main methods of the SList are:\n",
    "- `fields`: simulates `awk`\n",
    "- `grep`\n",
    "- `sort`\n",
    "\n",
    "Other methods are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SList__nlstr', '_SList__paths', '_SList__spstr', '__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'append', 'clear', 'copy', 'count', 'extend', 'fields', 'get_list', 'get_nlstr', 'get_paths', 'get_spstr', 'grep', 'index', 'insert', 'l', 'list', 'n', 'nlstr', 'p', 'paths', 'pop', 'remove', 'reverse', 's', 'sort', 'spstr']\n"
     ]
    }
   ],
   "source": [
    "print(dir(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df` command is a command line utility for reporting file system disk space usage. It can be used to show the free space on a Unix or Linux computer and to understand the filesystems that have been mounted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Size', '234Gi', '186Ki', '234Gi', '234Gi', 'auto_home']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_space = !df -h\n",
    "\n",
    "# Print the total size of the mounted volumes\n",
    "disk_space.fields(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setup.py', 'spark-script.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = !ls\n",
    "\n",
    "# Find the files with \".py\" in them\n",
    "ls.grep('\\.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullpath of the file: root/command-line-automation.ipynb\n",
      "fullpath of the file: root/data-engineering.ipynb\n",
      "fullpath of the file: root/data-pipeline.ipynb\n",
      "fullpath of the file: root/setup.py\n",
      "fullpath of the file: root/software-engineering.ipynb\n",
      "fullpath of the file: root/spark-script.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Find the files with \".py\" in them\n",
    "result = ls.grep('.py')\n",
    "\n",
    "# Extract the filenames\n",
    "for res in result:\n",
    "    filename = res.split()[-1]\n",
    "    \n",
    "    # Create the full path\n",
    "    fullpath = os.path.join('root', filename)\n",
    "    print(f\"fullpath of the file: {fullpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Shell Commands in Python with Subprocess\n",
    "\n",
    "The [subprocess](https://docs.python.org/3/library/subprocess.html#module-subprocess) module allows to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. The recommended approach to invoking subprocesses is to use the `run()` function for all use cases it can handle. Note that, for more advanced use cases, the underlying `Popen` interface can be used directly.\n",
    "\n",
    "We can run shell commands using `subprocess.run()` using Python 3.5+. It takes a list of strings, runs the command described its args, waits for command to complete, then returns a `CompletedProcess` instance.\n",
    "\n",
    "> If `shell` is `True`, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a userâ€™s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).\n",
    "\n",
    "_Note: It may be unsecure to use `shell=TRUE` in production._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['ls', '-l'], returncode=0)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "out = subprocess.run([\"ls\", \"-l\"])\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Unix sytems, successful comletion returns 0, whereas unsuccessful commands return non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print the value of the status code of the last command run\n",
    "!echo $?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "bad_out = subprocess.run([\"ls\", \"--asdf\"])\n",
    "\n",
    "print(bad_out.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture output\n",
    "out = subprocess.run([\"ls\", \"-l\"], capture_output=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "b'total 304\\n-rw-r--r--@ 1 stb  staff    118 Nov 30 09:04 README.md\\n-rw-r--r--  1 stb  staff  24761 Mar 24 17:28 command-line-automation.ipynb\\ndrwxr-xr-x  8 stb  staff    256 Feb  3 14:41 data\\n-rw-r--r--  1 stb  staff  54229 Jan 28 14:28 data-engineering.ipynb\\n-rw-r--r--  1 stb  staff   5933 Jan 30 00:27 data-pipeline.ipynb\\ndrwxr-xr-x  7 stb  staff    224 Jan 22 00:02 my_package\\n-rw-r--r--  1 stb  staff    310 Jan 22 00:31 setup.py\\n-rw-r--r--  1 stb  staff  38418 Jan 27 12:54 software-engineering.ipynb\\n-rw-r--r--@ 1 stb  staff    551 Dec  1 21:14 spark-script.py\\n-rw-r--r--  1 stb  staff   5865 Jan 22 00:21 stable-req.txt\\n'\n"
     ]
    }
   ],
   "source": [
    "print(type(out.stdout))\n",
    "\n",
    "# Byte Strings are default in subprocess\n",
    "print(out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total 304\\n-rw-r--r--@ 1 stb  staff    118 Nov 30 09:04 README.md\\n-rw-r--r--  1 stb  staff  24761 Mar 24 17:28 command-line-automation.ipynb\\ndrwxr-xr-x  8 stb  staff    256 Feb  3 14:41 data\\n-rw-r--r--  1 stb  staff  54229 Jan 28 14:28 data-engineering.ipynb\\n-rw-r--r--  1 stb  staff   5933 Jan 30 00:27 data-pipeline.ipynb\\ndrwxr-xr-x  7 stb  staff    224 Jan 22 00:02 my_package\\n-rw-r--r--  1 stb  staff    310 Jan 22 00:31 setup.py\\n-rw-r--r--  1 stb  staff  38418 Jan 27 12:54 software-engineering.ipynb\\n-rw-r--r--@ 1 stb  staff    551 Dec  1 21:14 spark-script.py\\n-rw-r--r--  1 stb  staff   5865 Jan 22 00:21 stable-req.txt\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = out.stdout\n",
    "\n",
    "# Decode byte strings to regular string\n",
    "res.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we can `touch` a file using the `subprocess` module and then inspect the permissions on the file that was created. (`os.stat` gives us useful metadata about files)\n",
    "\n",
    "The `touch` command is used in UNIX/Linux operating system to create, change and modify timestamps of a file. Basically, there are two different commands to create a file in the Linux system which is as follows:\n",
    "\n",
    "- `cat` command: It is used to create the file with content.\n",
    "- `touch` command: It is used to create a file without any content. The file created using touch command is empty. [ref](https://www.geeksforgeeks.org/touch-command-in-linux-with-examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File System NOT exported properly: 100 != 300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Setup\n",
    "file_location = \"data/dp/tmp.txt\"\n",
    "uid = 100\n",
    "\n",
    "# Touch a file\n",
    "proc = subprocess.Popen([\"touch\", file_location])\n",
    "\n",
    "# Check user permissions\n",
    "stat = os.stat(file_location)\n",
    "if stat.st_uid == 100:\n",
    "    print(f\"File System exported properly: {uid} == {stat.st_uid}\")\n",
    "else:\n",
    "    print(f\"File System NOT exported properly: {uid} != 300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `subprocess.run` was added in Python 3.5 as a simplification over subprocess. `Popen` when you just want to execute a command and wait until it finishes, but you don't want to do anything else meanwhile. For other cases, you still need to use `subprocess.Popen`. [stackoverflow](https://stackoverflow.com/questions/39187886/what-is-the-difference-between-subprocess-popen-and-subprocess-run/39187984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example to safely run two Unix commands in `subprocess.Popen`:\n",
    "\n",
    "- The Unix command `head` will read the first few lines and `wc -w` will count the total number of words.\n",
    "\n",
    "- Passing `stdout=subprocess.PIPE` into `Popen` captures the output of `wc`.\n",
    "\n",
    "- `stdout` captures output of command.\n",
    "\n",
    "- `stdout.read()` returns output as a string. \n",
    "\n",
    "- `stdout.readlines()` returns outputs as an interator.\n",
    "\n",
    "- `shell=False` is default and recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. \\n'\n",
      "b'This module intends to replace several older modules and functions:\\n'\n",
      "b'\\n'\n",
      "b'os.system\\n'\n",
      "b'os.spawn*\\n'\n",
      "b'\\n'\n",
      "b'Information about how the subprocess module can be used to replace these modules and functions can be found in the following sections.\\n'\n",
      "b'\\n'\n",
      "b'See also PEP 324 \\xe2\\x80\\x93 PEP proposing the subprocess module\\n'\n",
      "b'Using the subprocess Module\\n'\n"
     ]
    }
   ],
   "source": [
    "# Execute Unix command `head` safely as items in a list\n",
    "with subprocess.Popen([\"head\", \"data/dp/tmp.txt\"], stdout=subprocess.PIPE) as head:\n",
    "  \n",
    "    # Print each line of list returned by `stdout.readlines()`\n",
    "    for line in head.stdout.readlines():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'     122 data/dp/tmp.txt\\n'\n"
     ]
    }
   ],
   "source": [
    "# Execute Unix command `wc -w` safely as items in a list\n",
    "with subprocess.Popen([\"wc\", \"-w\", \"data/dp/tmp.txt\"], stdout=subprocess.PIPE) as word_count:\n",
    "  \n",
    "    # Print the string output of standard out of `wc -w`\n",
    "    print(word_count.stdout.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'alabaster', 'version': '0.7.12'},\n",
      " {'name': 'alembic', 'version': '1.3.1'}]\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# Use the with context manager to run subprocess.Popen()\n",
    "with Popen([\"pip\",\"list\",\"--format=json\"], stdout=PIPE) as proc:\n",
    "    # Pipe the output of subprocess.Popen() to stdout\n",
    "    result = proc.stdout.readlines()\n",
    "\n",
    "# Convert the JSON payload to a Python dictionary\n",
    "# JSON is a datastructure similar to a Python dictionary\n",
    "converted_result = json.loads(result[0])\n",
    "\n",
    "# Display the result in the IPython terminal (nicely formatted)\n",
    "pprint.pprint(converted_result[1:3], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can catch a process as it timed out `using proc.kill()` when the TimeoutExpired exception was triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process timed out with output: b'', error: b''\n"
     ]
    }
   ],
   "source": [
    "# Start a long running process using subprocess.Popen()\n",
    "proc = Popen([\"sleep\", \"4\"], stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "# Use subprocess.communicate() to create a timeout \n",
    "try:\n",
    "    output, error = proc.communicate(timeout=3)\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "\n",
    "\t# Cleanup the process if it takes longer than the timeout\n",
    "    proc.kill()\n",
    "    \n",
    "    # Read standard out and standard error streams and print\n",
    "    output, error = proc.communicate()\n",
    "    print(f\"Process timed out with output: {output}, error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting duplicate files with Subprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Duplicates: ['data/dp/tmp2.txt']\n"
     ]
    }
   ],
   "source": [
    "checksums = {}\n",
    "duplicates = []\n",
    "\n",
    "files = ['data/dp/tmp.txt', 'data/dp/tmp2.txt']\n",
    "\n",
    "# Iterate over the list of files filenames\n",
    "for filename in files:\n",
    "  \t# Use Popen to call the md5/md5sum utility\n",
    "    with Popen([\"md5\", filename], stdout=PIPE) as proc:\n",
    "        checksum = proc.stdout.read().split()[3]\n",
    "        \n",
    "        # Append duplicate to a list if the checksum is found\n",
    "        if checksum in checksums:\n",
    "            duplicates.append(filename)\n",
    "        \n",
    "        checksums[checksum] = filename\n",
    "\n",
    "print(f\"Found Duplicates: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending Input\n",
    "\n",
    "Two ways to send input to shell are:\n",
    "- run\n",
    "- Popen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# Run 'find' command to search for files\n",
    "find = subprocess.Popen(\n",
    "    [\"find\", \".\", \"-type\", \"f\", \"-print\"], stdout=subprocess.PIPE)\n",
    "\n",
    "# Run 'wc' and counts the number of lines\n",
    "word_count = subprocess.Popen(\n",
    "    [\"wc\", \"-l\"], stdin=find.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "# Print the decoded and formatted output\n",
    "output = word_count.stdout.read()\n",
    "print(output.decode(\"utf-8\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security Issues\n",
    "\n",
    "Security best practices for subprocesses:\n",
    "\n",
    "- Always use `shell=False` (`shell=True` allows arbitrary code)\n",
    "- Use `shlex` module to sanitize strings (when needed)\n",
    "- Reduce complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Using a Python list to safely pass arguments into the Unix `find` command to find all of the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts user input\n",
    "print(\"Enter a path to search for directories: \\n\")\n",
    "user_input = \".\"\n",
    "print(f\"directory to process: {user_input}\")\n",
    "\n",
    "#Pass safe user input into subprocess\n",
    "with subprocess.Popen([\"find\", user_input, \"-type\", \"d\"], stdout=subprocess.PIPE) as find:\n",
    "    result = find.stdout.readlines()\n",
    "    \n",
    "    #Process each line and decode it and strip it\n",
    "    for line in result:\n",
    "        formatted_line = line.decode(\"utf-8\").strip()\n",
    "        print(f\"Found Directory: {formatted_line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shlex` example: Getting the total storage of a list of directories.\n",
    "\n",
    "> We use the `shlex.split` command to create a safely run Unix tool that calculates disk usage. The key difference in `shlex.split` is that it can **safely quote unix strings** and prevent attack vectors versus a regular string split method that doesn't have this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a list of directories to calculate storage total: \n",
      "\n",
      "raw_user_input: data my_package |  sanitized_user_input: ['data', 'my_package']\n",
      "cmd: ['du', '-sh', '--total', 'data', 'my_package']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "\n",
    "print(\"Enter a list of directories to calculate storage total: \\n\")\n",
    "user_input = \"data my_package\"\n",
    "\n",
    "# Sanitize the user input\n",
    "sanitized_user_input = shlex.split(user_input)\n",
    "print(f\"raw_user_input: {user_input} |  sanitized_user_input: {sanitized_user_input}\")\n",
    "\n",
    "# Safely Extend the command with sanitized input\n",
    "cmd = [\"du\", \"-sh\", \"--total\"]\n",
    "cmd.extend(sanitized_user_input)\n",
    "print(f\"cmd: {cmd}\")\n",
    "\n",
    "# Print the totals out\n",
    "disk_total = subprocess.run(cmd, stdout=subprocess.PIPE)\n",
    "print(disk_total.stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walking the File System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for files that match specific patterns in a directory: Finding all `.csv` files. \n",
    "> Note, that this code could be made even more sophisticated by taking advantage of other Python features like looking for regular expressions in file content or performing machine learning on each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x108e5ac50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk('data/cla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/cla/train1.csv\n",
      "Processing file: data/cla/train3.csv\n",
      "Processing file: data/cla/train2.csv\n",
      "Processing file: data/cla/test/test3.csv\n",
      "Processing file: data/cla/test/test1.csv\n",
      "Processing file: data/cla/test/.ipynb_checkpoints/test1-checkpoint.csv\n",
      "Processing file: data/cla/.ipynb_checkpoints/train1-checkpoint.csv\n",
      "\n",
      "Matches:\n",
      " ['data/cla/train1.csv', 'data/cla/train3.csv', 'data/cla/train2.csv', 'data/cla/test/test3.csv', 'data/cla/test/test1.csv', 'data/cla/test/.ipynb_checkpoints/test1-checkpoint.csv', 'data/cla/.ipynb_checkpoints/train1-checkpoint.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "matches = []\n",
    "# Walk the filesystem starting at the data/cla\n",
    "for root, _, files in os.walk('data/cla'):\n",
    "    for name in files:\n",
    "      \t# Create the full path to the file by using os.path.join()\n",
    "        fullpath = os.path.join(root, name)\n",
    "        print(f\"Processing file: {fullpath}\")\n",
    "        # Split off the extension and discard the rest of the path\n",
    "        _, ext = os.path.splitext(fullpath)\n",
    "        # Match the extension pattern .csv\n",
    "        if ext == \".csv\":\n",
    "            matches.append(fullpath)\n",
    "            \n",
    "# Print the matches you find          \n",
    "print('\\nMatches:\\n', matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/cla/train_1.csv\n",
      "Renaming file train_1.csv to tr_1.csv\n",
      "Processing file: data/cla/test/test3.csv\n",
      "Processing file: data/cla/test/test1.csv\n",
      "Processing file: data/cla/test/.ipynb_checkpoints/test1-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Walk the filesystem\n",
    "for root, _, files in os.walk('data/cla'):\n",
    "    for name in files:\n",
    "      \t\n",
    "        # Create the full path to the file\n",
    "        fullpath = os.path.join(root, name)\n",
    "        print(f\"Processing file: {fullpath}\")\n",
    "        \n",
    "        # Rename file\n",
    "        if \"train\" in name:\n",
    "            p = pathlib.Path(fullpath)\n",
    "            num_ext = name.split(\"_\")[1]  # Split the name by underscore\n",
    "            new_name = f\"tr_{num_ext}\"\n",
    "            print(f\"Renaming file {name} to {new_name}\")\n",
    "            p.rename(new_name)\n",
    "            \n",
    "#### Saves the renamed file to the root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Files Matching a Pattern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
